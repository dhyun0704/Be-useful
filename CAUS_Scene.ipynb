{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Envirionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install openai\n",
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('openai_api_key.txt', 'r') as f:\n",
    "    openai.api_key = f.read().strip()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "os.environ.get(\"OPENAI_API_KEY\") # api_key 확인 필요할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling prompts\n",
    "with open('sprompt_int.txt', 'r') as f:\n",
    "    sprompt_int = f.read()\n",
    "\n",
    "with open('sprompt_obj.txt', 'r') as f:\n",
    "    sprompt_obj = f.read()\n",
    "\n",
    "with open('sprompt_plt.txt', 'r') as f:\n",
    "    sprompt_plt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the prompt\n",
    "print(sprompt_int[50:120])\n",
    "print(sprompt_obj[50:120])\n",
    "print(sprompt_plt[50:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene Genaration with Langchain Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [cls0] OBJECT UNCERTAINTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBJECT UNCERTAINTY\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4-0613\", temperature=0.7)\n",
    "output = []\n",
    "\n",
    "for _ in range(1):\n",
    "    messages = [\n",
    "        SystemMessage(content=f\"'{sprompt_obj}'\"),\n",
    "        HumanMessage(content=\"Write sentences each about a situation with an ordinary object that is out of context.\"),\n",
    "        ]\n",
    "\n",
    "    scene = chat(messages)\n",
    "    scene_list = [scene.content] # Etracting only the content of the AIMessage as dict\n",
    "    \n",
    "    output.append(scene_list)\n",
    "    output_list = ';'.join([','.join(lst) for lst in output])\n",
    "\n",
    "    # 세미콜론 기준으로 문자열 분리하고 리스트 생성\n",
    "split_output_lists = [s.strip().split(\"',\") for s in output_list.split(';')]\n",
    "\n",
    "# Flatten list 로 변환 후 cls 0 DataFrame 생성\n",
    "flat_list = [item[0] for item in split_output_lists]\n",
    "df0 = pd.DataFrame({\n",
    "    'scn_sentence': flat_list,\n",
    "    'scn_cls': [0] * len(flat_list)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [cls1] INTENTION UNCERTAINTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTENTION UNCERTAINTY\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=1)\n",
    "output = []\n",
    "\n",
    "for _ in range(1):\n",
    "    messages = [\n",
    "        SystemMessage(content=f\"'{sprompt_int}'\"),\n",
    "        HumanMessage(content=\"Write short sentences each of which is about a realistic situation that gives a question mark about a character's behavior.\"),\n",
    "        ]\n",
    "\n",
    "    scene = chat(messages)\n",
    "    scene_list = [scene.content] # Etracting only the content of the AIMessage as dict\n",
    "    \n",
    "    output.append(scene_list)\n",
    "    output_list = ';'.join([','.join(lst) for lst in output])\n",
    "\n",
    "    # 세미콜론 기준으로 문자열 분리하고 리스트 생성\n",
    "split_output_lists = [s.strip().split(\"',\") for s in output_list.split(';')]\n",
    "\n",
    "# Flatten list 로 변환 후 cls 1 DataFrame 생성\n",
    "flat_list = [item[0] for item in split_output_lists]\n",
    "df1 = pd.DataFrame({\n",
    "    'scn_sentence': flat_list,\n",
    "    'scn_cls': [1] * len(flat_list)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cls[2] EVENT UNCERTAINTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVENT UNCERTAINTY\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4-0613\", temperature=1)\n",
    "output = []\n",
    "\n",
    "for _ in range(1):\n",
    "    messages = [\n",
    "        SystemMessage(content=f\"'{sprompt_plt}'\"),\n",
    "        HumanMessage(content=\"Write sentences that depict a noticeable change in a common scenario involving a person or object.\"),\n",
    "        ]\n",
    "\n",
    "    scene = chat(messages)\n",
    "    scene_list = [scene.content] # Etracting only the content of the AIMessage as dict\n",
    "    \n",
    "    output.append(scene_list)\n",
    "    output_list = ';'.join([','.join(lst) for lst in output])\n",
    "\n",
    "    # 세미콜론 기준으로 문자열 분리하고 리스트 생성\n",
    "split_output_lists = [s.strip().split(\"',\") for s in output_list.split(';')]\n",
    "\n",
    "# Flatten list 로 변환 후 cls 2 DataFrame 생성\n",
    "flat_list = [item[0] for item in split_output_lists]\n",
    "df2 = pd.DataFrame({\n",
    "    'scn_sentence': flat_list,\n",
    "    'scn_cls': [2] * len(flat_list)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 데이터프레임을 row-wise로 합침\n",
    "df = pd.concat([df0, df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 무작위로 생성된 ID를 기준으로 정렬한 최종 df 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자새 개와 알파벳을 섞어서 고유한 난수를 생성\n",
    "def generate_random_id():\n",
    "    numbers = ''.join(random.sample(string.digits, 3))  # 3개의 숫자 선택\n",
    "    letters = ''.join(random.sample(string.ascii_uppercase, 3))  # 3개의 대문자 알파벳 선택\n",
    "    # 알파벳과 숫자를 합친 후 무작위로 섞는다.\n",
    "    random_id = ''.join(random.sample(numbers + letters, 6))\n",
    "    return random_id\n",
    "\n",
    "# 중복되지 않는 난수를 생성\n",
    "unique_ids = set()\n",
    "while len(unique_ids) < len(df):\n",
    "    unique_id = generate_random_id()\n",
    "    if unique_id not in unique_ids:\n",
    "        unique_ids.add(unique_id)\n",
    "\n",
    "# 각 문장에 대한 난수 ID를 DataFrame 가장 왼쪽에 새로운 열을 삽입하는 방식으로 추가\n",
    "df.insert(0, 'scn_id', list(unique_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'scn_id'를 기준으로 오름차순 정렬 (해도 되고 안 해도 되고)\n",
    "df = df.sort_values(by='scn_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of output file\n",
    "FileName = '0904_add_75_kdh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "df.to_csv(f'_output_scene/{FileName}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
