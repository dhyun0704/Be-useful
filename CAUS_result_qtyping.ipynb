{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Envirionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install openai\n",
    "! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('openai_api_key.txt', 'r') as f:\n",
    "    openai.api_key = f.read().strip()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "# os.environ.get(\"OPENAI_API_KEY\") # api_key 확인 필요할 때\n",
    "\n",
    "# models = dict(openai.Model.list())\n",
    "# for i in models['data']:\n",
    "#     if i['id'].startswith('gpt'):\n",
    "#         print(i['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('_output_scene/scene_curated_0831.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling prompts\n",
    "with open('rprompt.txt', 'r') as f:\n",
    "    rprompt = f.read()\n",
    "\n",
    "with open('qprompt.txt', 'r') as f:\n",
    "    qprompt = f.read()\n",
    "\n",
    "with open('qtype_prompt.txt', 'r') as f:\n",
    "    qt_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rprompt[:50])\n",
    "# print(qprompt[:50])\n",
    "print(qt_prompt[450:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring reasoning and queries from scene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4-0613\", temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First loop for reasoning and questioning from scene lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 루프: reasoning과 query_value를 생성합니다.\n",
    "intermediate_results = []\n",
    "for i, row in df.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    SceneDescription = row[1]\n",
    "    \n",
    "    messages = [SystemMessage(content=f\"'{rprompt}'\"), HumanMessage(content=f\"'{SceneDescription}'\")]\n",
    "    reasoning = chat(messages).content\n",
    "\n",
    "    messages = [SystemMessage(content=f\"'{qprompt}'\"), HumanMessage(content=f\"'{SceneDescription}'\")]\n",
    "    query = chat(messages)\n",
    "    query_value = [s.strip() for s in query.content.split(';')]\n",
    "\n",
    "    intermediate_results.append({\n",
    "        'row_dict': row_dict,\n",
    "        'reasoning': reasoning,\n",
    "        'query_value': query_value\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving intermediate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of output file\n",
    "FileName = '0831v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the intermediate_results to a JSON file\n",
    "\n",
    "with open(f'_output_result/intermediate_{FileName}.json', 'w') as json_file:\n",
    "    json.dump(intermediate_results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second loop for qtyping from the intermediate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간저장한 intermediate file 불러오기\n",
    "with open(f'_output_result/intermediate_{FileName}.json', 'r') as file:\n",
    "    intermediate_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 루프 - ratelimiterror 회피하기 위한 속도 조절 버전\n",
    "# 각 query_value에 대해 qtype 처리 후 결과 생성\n",
    "output = []\n",
    "\n",
    "# 5개씩 끊어서 처리\n",
    "for i in range(0, len(intermediate_json), 5):\n",
    "    chunk = intermediate_json[i:i+5]\n",
    "\n",
    "    for item in chunk:\n",
    "        row_dict = item['row_dict']\n",
    "        reasoning = item['reasoning']\n",
    "        query_value = item['query_value']\n",
    "        \n",
    "        # qtype 처리\n",
    "        messages = [SystemMessage(content=f\"'{qt_prompt}'\"), HumanMessage(content=f\"'{query_value}'\")]\n",
    "        qtype_str = chat(messages).content\n",
    "        matches = re.findall(r\"\\(([^)]+)\\)\", qtype_str)    \n",
    "        qtype = [tuple(map(lambda x: x.strip().strip(\"'\"), match.split(','))) for match in matches]\n",
    "\n",
    "        # question 리스트 생성\n",
    "        questions_list = []\n",
    "        for idx, (query, (qtype_num, qtype_text)) in enumerate(zip(query_value, qtype), start=1):\n",
    "            question_dict = {\n",
    "                f\"qid{idx:02}\": f\"{row_dict['scn_id']}Q0{idx}\",\n",
    "                f\"question{idx:02}\": query,\n",
    "                f\"q_type_num{idx:02}\": qtype_num,\n",
    "                f\"q_type{idx:02}\": qtype_text\n",
    "            }\n",
    "            questions_list.append(question_dict)\n",
    "\n",
    "        # 최종 결과 생성\n",
    "        output_dict = {\n",
    "            \"scn_id\": row_dict[\"scn_id\"],\n",
    "            \"scn_cls\": row_dict[\"scn_cls\"],\n",
    "            \"scn_sentence\": row_dict[\"scn_sentence\"],\n",
    "            \"reasoning\": reasoning,  \n",
    "            \"question\": questions_list\n",
    "        }\n",
    "        output.append(output_dict)\n",
    "\n",
    "    # 5개 처리 후 10초 휴식\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving output to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the JSON output to a file\n",
    "\n",
    "with open(f'_output_result/result_{FileName}.json', 'w') as json_file:\n",
    "    json.dump(output, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving CSV with qid and qtypes of each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_output = []\n",
    "\n",
    "for entry in output:\n",
    "        new_dict = entry.copy() # 기존 딕셔너리의 복사본을 생성    \n",
    "        questions = new_dict.pop('question') # \"question\" 항목을 추출\n",
    "        for q_dict in questions:\n",
    "            new_dict.update(q_dict) # 각 하위 딕셔너리의 항목들을 상위 딕셔너리로 이동\n",
    "\n",
    "        transformed_output.append(new_dict) # 변형된 딕셔너리를 새로운 리스트에 추가\n",
    "\n",
    "# 새로운 리스트를 사용하여 DataFrame을 생성\n",
    "df_output = pd.DataFrame(transformed_output)\n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "df_output.to_csv(f'_output_result/result_{FileName}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
